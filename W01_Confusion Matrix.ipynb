{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although standard libraries are available for the confusion matrix, it can be helpful to program it yourself to gain more insight. In this notebook you will program the confusion matrix yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we will work with a standard dataset, which is available from TensorFlow to train a network: the so-called <a href=\"\"> Fashion MNIST </a>. The full network is given: study the code to get an idea of how this works. In the second part of this Notebook we will calculate and draw a confusion matrix based on this network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import randint\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_matrix(data):\n",
    "    plt.figure()\n",
    "    plt.matshow(data)\n",
    "    plt.show()\n",
    "    \n",
    "def scale_data(X):\n",
    "    m = np.max(X)\n",
    "    return X/m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load and split the data. After this we make a list, with which we can translate the labels from the dataset (numbers) into clearer terms (strings). This can take a while (especially the first time), so we will print a text when it is ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.fashion_mnist \n",
    "(train_images, train_labels), (test_images, test_labels) = data.load_data()\n",
    "labels = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandals', 'Shirt', 'Sneaker', 'Bag', 'Boot'] \n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Format train_images: {}\".format(train_images.shape))\n",
    "print (\"Formattrain_labels: {}\".format(train_labels.shape))\n",
    "print (\"Format test_images: {}\".format(test_images.shape))\n",
    "print (\"Formattest_labels: {}\".format(test_labels.shape))\n",
    "print (\"Size labels: {}\".format(len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we draw a random element from the training data. To make it clear what it is, we also label it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img, label):\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    plt.xlabel(label)\n",
    "    plt.show()\n",
    "\n",
    "rnd = randint(0, train_images.shape[0])\n",
    "hyp = labels[train_labels[rnd]]\n",
    "plot_image(train_images[rnd], hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that the values of the data are a number between 0 and 1; for this we use the auxiliary function `scale_data ()`, which we created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = scale_data(train_images)\n",
    "test_images = scale_data(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we create the network that we will use to train the data. The images consist of a matrix of 28 $ \\ times $ 28 pixels, so the input layer is a vector of 784 nodes. We connect this input completely to a second layer of 128 nodes, to eventually have an output layer of 10 nodes (one node for each possible class). Graphically, that network then looks like this:\n",
    "\n",
    "<img src=\"images/netwerk.png\" style=\"width:40vw;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will use the test data to determine how well our trained network is. As explained, the accuracy in itself is not sufficient to determine the performance of a classifier: if you would just gamble you would already have a score of ten percent for ten possible categories, and if you were to guess that a sample is not something accuracy even ninety percent. Better metrics for this are given by the confusion matrix, which is discussed during the theoretical part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/confusion_matrix.png\" style=\"width:30vw;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, complete the method `conf_matrix ()`. As you can see, this method gets two parameters, namely the values predicted by the network, and the actual values. Use the confusion_matrix method in TensorFlow to determine this matrix. Return the array.\n",
    "\n",
    "In the second part of the cell is the method, with the predictions based on `test_images` and actual values of that test-data (` test_labels`). The result is then plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(labels, pred):\n",
    "    # Return the confusion matrix based on the given prediction and the current one\n",
    "    # values (labels).\n",
    "    # Check eventueel de documentatie van tf.math.confusion_matrix:\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "pred = np.argmax(model.predict(test_images), axis=1)\n",
    "data = np.array(conf_matrix(test_labels, pred))\n",
    "print(type(data))\n",
    "plot_matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract more metrics from the trained model, not only the percentage of samples that are correctly classified is sufficient; we must therefore know which percentage is rightly classified as not of a certain class, which incorrectly as of a certain class, and which percentage is incorrectly classified as of a certain class: the so-called *true positives*, *true negatives*, *false positives* and *false negatives* (as discussed in the theoretical part)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `conf_els ()` in the cell below takes as a parameter the same numpy array that also underlies the image you created above. The *lines* of this matrix correspond to the actual value of the sample, the *columns* of this matrix correspond to the prediction of the sample by the model. Although semantically there are some remarks to be made, we define the above-described metrics as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">$tp_{i} = c_{ii}$</p>\n",
    "<p style=\"text-align:center\">$fp_{i} = \\sum_{l=1}^n c_{li} - tp_{i}$<</p>\n",
    "<p style=\"text-align:center\">$fn_{i} = \\sum_{l=1}^n c_{il} - tp_{i}$<br/></p>\n",
    "<p style=\"text-align:center\">$tn_{i} = \\sum_{l=1}^n \\sum_{k=1}^n c_{lk} -tp_{i} - fp_{i} - fn_{i}$</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ I $ is the category in question (so in this specific case it runs from 1 - 10). Implement the `conf_els ()` method, and return a list of these four metrics for each label - study the part of the implementation already given to get an idea of the exact form of the return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_els(conf, labels): \n",
    "    # This method takes a confusion matrix (conf) and a set of labels. If it is good, it is\n",
    "    # the dimensionality of the matrix equal to len (labels) Ã— len (labels) (why?). Calculate the\n",
    "    # values of the TP, FP, FN and TN in accordance with the calculation in the statement. Then make use of\n",
    "    # the zip () and list () methods to return a list of len (labels), with each tuple\n",
    "    # is defined as follows: \n",
    "\n",
    "    #     (category:string, tp:int, fp:int, fn:int, tn:int)\n",
    " \n",
    "    # Check de documentatie van numpy diagonal om de eerste waarde te bepalen.\n",
    "    # https://docs.scipy.org/doc/numpy/reference/generated/numpy.diagonal.html\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the method `conf_data ()`, in which you convert the data you created in the previous exercise into the following metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">$sensitivity (TPR) = \\frac{tp}{tp + fn}$</p>\n",
    "<p style=\"text-align:center\">$precision (PPV) = \\frac{tp}{tp + fp}$</p>\n",
    "<p style=\"text-align:center\">$specificity (TNR) = \\frac{tn}{tn + fp}$</p>\n",
    "<p style=\"text-align:center\">$fall-out (FPR) = \\frac{fp}{fp + tn}$</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method gets the list from the previous problem: the total is then the sum of all $ tp $ 's of all labels - and similar calculations for the total $ tn $, $ fp $ and $ fn $. Return this data as a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_data(metrics):\n",
    "    # This method gets the list you made in the previous exercise (so with len (labels))\n",
    "    # Use a list comprehension to calculate the total tp, fp, fn, and tn and\n",
    "    # then determine the metrics mentioned in the statement. Return these values in the\n",
    "    # form of a dictionary (the scaffold of this is given).\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have implemented both of these methods, you can run the script in the cell below; here these values are calculated and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = conf_els(data,labels)\n",
    "print (metrics)\n",
    "print (\"Bepalen van de scores:\")\n",
    "scores = conf_data(metrics)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you say something about the quality of the programmed network based on these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
