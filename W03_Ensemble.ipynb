{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Ensemble learning and Random Forest\n\n\nThis is a notebook to learn about different optimization techniques. First libraries are loaded and a dataset is loaded. The data is prepared for the machine learning algorithms and splitted into a training set and a test set. Different classifiers are tried and evaluated. After that different ensemble methods are applied to improve the performance. The learning outcomes of this exercise are\n\n1. understand the differences in methodologies \n2. apply these to your own dataset. Bring your own or choose one from  http://archive.ics.uci.edu/ml/index.php \n\n#### Solve the following\n1. Review the code below briefly. What are the repeating parts?\n2. Run the code for a different dataset\n3. For every classifier assess possible overfit (implement code for this)\n4. Implement a Naive Bayes classifier as well\n5. Explain the difference between RandomForest and Voting Classifier\n6. Explain the difference between hard and soft voting\n7. Explain the difference between bagging and stacking \n8. Adjust the bagging classifier in such way that it uses another algorithm \n9. Implement stacking \n10. Implement gradient boosting\n11. What algorithm can you use for very big datasets, and why\n12. What is the best strategy to find an optimal model for your chosen dataset\n\nYou can use any sources to find the answers. More information is to be found in the book, the presentation and the internet. The 11 questions and small assignments are a guideline to get familiar with the material. You are encouraged to explore more configurations."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Load Libraries"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/matplotlib/font_manager.py:281: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n  from numpy.core.umath_tests import inner1d\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Load and prepare Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = pd.read_pickle('../data/breast_cancer.pkl')\ndf.head()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../data/breast_cancer.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/breast_cancer.pkl'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/breast_cancer.pkl'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/breast_cancer.pkl'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/breast_cancer.pkl'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/breast_cancer.pkl'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9c9f45cabc08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/breast_cancer.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/breast_cancer.pkl'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "#X en y\ncols = [\n        'texture_mean', \n        'area_mean', \n        'smoothness_mean', \n        'compactness_mean', \n        'concavity_mean',\n        'concave points_mean', \n        'symmetry_mean', \n        'fractal_dimension_mean']\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y = np.array(df['diagnosis'])\nX = np.array(df[cols])\nX.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#normalize\nfrom sklearn.preprocessing import StandardScaler\n\ndef normalize(X):\n    scalar = StandardScaler()\n    scalar = scalar.fit(X)\n    X = scalar.transform(X)\n    return X\n\nX = normalize(X)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "---\n# Try different classifiers"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Logistic"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#train\nfrom sklearn.linear_model import LogisticRegression\n\nlg = LogisticRegression()\nlg.fit(X_train, y_train)",
      "execution_count": 7,
      "outputs": [
        {
          "data": {
            "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# evaluation\ny_pred = lg.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[101   2]\n [  6  62]]\n              precision    recall  f1-score   support\n\n         0.0       0.94      0.98      0.96       103\n         1.0       0.97      0.91      0.94        68\n\n    accuracy                           0.95       171\n   macro avg       0.96      0.95      0.95       171\nweighted avg       0.95      0.95      0.95       171\n\n"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# compare accuracy train versus test to access overfit \nprint(lg.score(X_test, y_test))\nprint(lg.score(X_train, y_train))",
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "0.9532163742690059\n0.9472361809045227\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Decision Tree"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)",
      "execution_count": 10,
      "outputs": [
        {
          "data": {
            "text/plain": "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                       max_depth=None, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')"
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = dt.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(dt.score(X_test, y_test))\nprint(dt.score(X_train, y_train))",
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[94  9]\n [ 4 64]]\n              precision    recall  f1-score   support\n\n         0.0       0.96      0.91      0.94       103\n         1.0       0.88      0.94      0.91        68\n\n    accuracy                           0.92       171\n   macro avg       0.92      0.93      0.92       171\nweighted avg       0.93      0.92      0.92       171\n\n0.9239766081871345\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## SVM \n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "svm = SVC(kernel='rbf')\nsvm.fit(X_train, y_train)",
      "execution_count": 12,
      "outputs": [
        {
          "data": {
            "text/plain": "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)"
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = svm.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(svm.score(X_test, y_test))",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[102   1]\n [  6  62]]\n              precision    recall  f1-score   support\n\n         0.0       0.94      0.99      0.97       103\n         1.0       0.98      0.91      0.95        68\n\n    accuracy                           0.96       171\n   macro avg       0.96      0.95      0.96       171\nweighted avg       0.96      0.96      0.96       171\n\n0.9590643274853801\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Naive Bayes"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Implement code here",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "---\n# Ensemble learning"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Random Forest"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "rf = RandomForestClassifier(n_estimators = 10)\nrf.fit(X_train, y_train)",
      "execution_count": 15,
      "outputs": [
        {
          "data": {
            "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=10,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = rf.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(rf.score(X_test, y_test))",
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[98  5]\n [ 8 60]]\n              precision    recall  f1-score   support\n\n         0.0       0.92      0.95      0.94       103\n         1.0       0.92      0.88      0.90        68\n\n    accuracy                           0.92       171\n   macro avg       0.92      0.92      0.92       171\nweighted avg       0.92      0.92      0.92       171\n\n0.9239766081871345\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Bagging with Decicion Tree classifier"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "bg = BaggingClassifier(DecisionTreeClassifier(), max_features = 1.0, max_samples = 0.5) \nbg.fit(X_train, y_train)",
      "execution_count": 17,
      "outputs": [
        {
          "data": {
            "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n                                                        class_weight=None,\n                                                        criterion='gini',\n                                                        max_depth=None,\n                                                        max_features=None,\n                                                        max_leaf_nodes=None,\n                                                        min_impurity_decrease=0.0,\n                                                        min_impurity_split=None,\n                                                        min_samples_leaf=1,\n                                                        min_samples_split=2,\n                                                        min_weight_fraction_leaf=0.0,\n                                                        presort='deprecated',\n                                                        random_state=None,\n                                                        splitter='best'),\n                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n                  max_samples=0.5, n_estimators=10, n_jobs=None,\n                  oob_score=False, random_state=None, verbose=0,\n                  warm_start=False)"
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = bg.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(bg.score(X_test, y_test))",
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[97  6]\n [ 5 63]]\n              precision    recall  f1-score   support\n\n         0.0       0.95      0.94      0.95       103\n         1.0       0.91      0.93      0.92        68\n\n    accuracy                           0.94       171\n   macro avg       0.93      0.93      0.93       171\nweighted avg       0.94      0.94      0.94       171\n\n0.935672514619883\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Boosting"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "adb = AdaBoostClassifier(LogisticRegression(), n_estimators = 10, learning_rate = 1)\nadb.fit(X_train, y_train)",
      "execution_count": 19,
      "outputs": [
        {
          "data": {
            "text/plain": "AdaBoostClassifier(algorithm='SAMME.R',\n                   base_estimator=LogisticRegression(C=1.0, class_weight=None,\n                                                     dual=False,\n                                                     fit_intercept=True,\n                                                     intercept_scaling=1,\n                                                     l1_ratio=None,\n                                                     max_iter=100,\n                                                     multi_class='auto',\n                                                     n_jobs=None, penalty='l2',\n                                                     random_state=None,\n                                                     solver='lbfgs', tol=0.0001,\n                                                     verbose=0,\n                                                     warm_start=False),\n                   learning_rate=1, n_estimators=10, random_state=None)"
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = adb.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(adb.score(X_test, y_test))",
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[103   0]\n [  6  62]]\n              precision    recall  f1-score   support\n\n         0.0       0.94      1.00      0.97       103\n         1.0       1.00      0.91      0.95        68\n\n    accuracy                           0.96       171\n   macro avg       0.97      0.96      0.96       171\nweighted avg       0.97      0.96      0.96       171\n\n0.9649122807017544\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Stacking"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Your code here",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Gradient Boosting"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Your code here",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Voting classifier"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "evc = VotingClassifier(estimators = [('dt', dt), ('lg',lg), ('svm', svm)], voting = 'hard')\nevc.fit(X_train, y_train)",
      "execution_count": 23,
      "outputs": [
        {
          "data": {
            "text/plain": "VotingClassifier(estimators=[('dt',\n                              DecisionTreeClassifier(ccp_alpha=0.0,\n                                                     class_weight=None,\n                                                     criterion='gini',\n                                                     max_depth=None,\n                                                     max_features=None,\n                                                     max_leaf_nodes=None,\n                                                     min_impurity_decrease=0.0,\n                                                     min_impurity_split=None,\n                                                     min_samples_leaf=1,\n                                                     min_samples_split=2,\n                                                     min_weight_fraction_leaf=0.0,\n                                                     presort='deprecated',\n                                                     random_state=None,\n                                                     splitter='best')),\n                             ('lg',\n                              LogisticR...\n                                                 solver='lbfgs', tol=0.0001,\n                                                 verbose=0, warm_start=False)),\n                             ('svm',\n                              SVC(C=1.0, break_ties=False, cache_size=200,\n                                  class_weight=None, coef0=0.0,\n                                  decision_function_shape='ovr', degree=3,\n                                  gamma='scale', kernel='rbf', max_iter=-1,\n                                  probability=False, random_state=None,\n                                  shrinking=True, tol=0.001, verbose=False))],\n                 flatten_transform=True, n_jobs=None, voting='hard',\n                 weights=None)"
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = evc.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(evc.score(X_test, y_test))",
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[101   2]\n [  5  63]]\n              precision    recall  f1-score   support\n\n         0.0       0.95      0.98      0.97       103\n         1.0       0.97      0.93      0.95        68\n\n    accuracy                           0.96       171\n   macro avg       0.96      0.95      0.96       171\nweighted avg       0.96      0.96      0.96       171\n\n0.9590643274853801\n"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}